How to use and seting Quota option in Glusterfs on Ubuntu 16.04.3 LTS

 Applying quota on directory is very common requirement. 
 In case of gluterfs we are also having the provision of applying the quota on directories. 
 In this article I am going to show how to use quota option in Glusterfs.
 
Step 1 : Before applying the quota on directory which is present in volume we need to enable the quota option at volume level.
# gluster vol quota test1-vol enable
  volume quota : success

 Step 2 : I have mounted the volume on client at mountpoint (/mnt) and I have created one directory beneath  it.
  # mount -t glusterfs dcosdemo03:/test1-vol /glsfs/
  # mkdir -p /glsfs/folder1;mkdir -p /glsfs/folder2
  
  We can defined use below command initially while defining the hard limit.
  # gluster vol quota test1-vol limit-usage /folder1 100MB
     volume quota : success
  # gluster vol quota test1-vol limit-usage /folder2 100MB
   volume quota : success
 ###here is the information for quota status on volume.###
 # gluster vol quota test1-vol list
                  Path                   Hard-limit  Soft-limit      Used  Available  Soft-limit exceeded? Hard-limit exceeded?
 -------------------------------------------------------------------------------------------------------------------------------
/folder1                                 100.0MB     80%(80.0MB)   0Bytes 100.0MB              No                   No
/folder2                                 100.0MB     80%(80.0MB)   0Bytes 100.0MB              No                   No

we also can use command as below change while modify the soft limit.
# gluster vol quota test1-vol limit-usage /folder2 100MB 90%
  volume quota : success

GlusterFS tuning:
# gluster volume quota test1-vol limit-usage / 29.0GB
  volume quota : success
# gluster volume set test1-vol performance.cache-size 4GB (Default 32MB)
  volume set: success
# gluster volume set test1-vol performance.io-thread-count 16 (ensure thread not more than 16)
  volume set: success
# gluster volume set test1-vol network.ping-timeout 10 (Default 42s)
  volume set: success
# gluster volume set test1-vol performance.write-behind-window-size 1024MB (Default 1M)
  volume set: success
 # gluster volume info

Volume Name: test1-vol
Type: Replicate
Volume ID: ebc88227-1b0b-4390-abb8-bee0622b43ca
Status: Started
Number of Bricks: 1 x 3 = 3
Transport-type: tcp
Bricks:
Brick1: dcosdemo03:/data/test1
Brick2: dcosdemo04:/data/test1
Brick3: dcosdemo05:/data/test1
Options Reconfigured:
performance.write-behind-window-size: 1024MB
network.ping-timeout: 10
performance.io-thread-count: 16
performance.cache-size: 4GB
features.quota-deem-statfs: on
features.inode-quota: on
features.quota: on
performance.readdir-ahead: on 
  
